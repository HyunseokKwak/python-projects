{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 Python GDAL/OGR Cookbook\n",
    "https://pcjericks.github.io/py-gdalogr-cookbook/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import glob\n",
    "from osgeo import ogr, osr, gdal\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 메타데이터 읽어보자\n",
    "idx, inv, ctl 파일이 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gfsanl_3_20040401_0000_000.txt','r') as fp:\n",
    "    inv = fp.read()\n",
    "    bands = inv.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0:D=2004040100:HGT:1000 mb:kpds=7,100,1000:anl:winds are N/S:\"Geopotential height [gpm]\n",
      "2:105968:D=2004040100:HGT:975 mb:kpds=7,100,975:anl:winds are N/S:\"Geopotential height [gpm]\n",
      "3:211936:D=2004040100:HGT:950 mb:kpds=7,100,950:anl:winds are N/S:\"Geopotential height [gpm]\n",
      "4:317904:D=2004040100:HGT:925 mb:kpds=7,100,925:anl:winds are N/S:\"Geopotential height [gpm]\n",
      "5:423872:D=2004040100:HGT:900 mb:kpds=7,100,900:anl:winds are N/S:\"Geopotential height [gpm]\n",
      "6:529840:D=2004040100:HGT:850 mb:kpds=7,100,850:anl:winds are N/S:\"Geopotential height [gpm]\n",
      "7:643954:D=2004040100:HGT:800 mb:kpds=7,100,800:anl:winds are N/S:\"Geopotential height [gpm]\n",
      "8:758068:D=2004040100:HGT:750 mb:kpds=7,100,750:anl:winds are N/S:\"Geopotential height [gpm]\n",
      "9:872182:D=2004040100:HGT:700 mb:kpds=7,100,700:anl:winds are N/S:\"Geopotential height [gpm]\n",
      "10:986296:D=2004040100:HGT:650 mb:kpds=7,100,650:anl:winds are N/S:\"Geopotential height [gpm]\n"
     ]
    }
   ],
   "source": [
    "for band in bands[:10]: #len(bands)==284\n",
    "    print(band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSET ^gfsanl_3_20040401_0000_000.grb\n",
      "\n",
      "INDEX ^gfsanl_3_20040401_0000_000.idx\n",
      "undef 9.999E+20\n",
      "*\n",
      "title Global Forecast System : 20040401 0000 UTC cycle - Analysis only\n",
      "*\n",
      "options yrev\n",
      "dtype grib 3\n",
      "xdef 360 linear   0 1\n",
      "ydef 181 linear -90 1\n",
      "tdef 1 linear 00:00z01apr2004 3hr\n",
      "zdef 26 levels\n",
      "1000 975 950 925 900 850 800 750 700 650 600 550 500 450 400 350 300 \n",
      "250 200 150 100 70 50 30 20 10 \n",
      "*\n",
      "vars 145\n",
      "no4LFTX  0 132,1,0      surface Best (4-layer) lifted index [K]\n",
      "no5WAVH  0 222,100,500  ** -5-wave geopotential height [gpm]\n",
      "ABSV     26 41,100,0    Absolute vorticity [/s]\n",
      "ACPCP    0 63,1,0       surface Convective precipitation [kg/m^2] \n",
      "APCP     0 61,1,0       surface Total precipitation [kg/m^2] \n",
      "CAPE     0 157,1,0      surface Convective Avail. Pot. Energy [J/kg]\n",
      "CAPE180_0mb 0 157,116,46080 ** 180-0 mb above gnd Convective Avail. Pot. Energy [J/kg]\n",
      "oCFRZR   0 141,1,0      surface Categorical freezing rain [yes=1 no=0] \n",
      "oCICEP   0 142,1,0      surface Categorical ice pellets [yes=1 no=0] \n",
      "C\n"
     ]
    }
   ],
   "source": [
    "with open('gfsanl_3_20040401_0000_000_ctl.txt','r') as fp:\n",
    "    ctl = fp.read()\n",
    "print(ctl[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터인 grb를 읽어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds =gdal.Open('gfsanl_3_20040401_0000_000.grb') # grb를 읽어 gdal.Dataset으로 받아옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "osgeo.gdal.Dataset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Number: 2\n",
      "Error Type: Debug\n",
      "Error Message: test error\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     from osgeo import ogr, osr, gdal\n",
    "# except:\n",
    "#     sys.exit('ERROR: cannot find GDAL/OGR modules')\n",
    "\n",
    "# # example GDAL error handler function\n",
    "# def gdal_error_handler(err_class, err_num, err_msg):\n",
    "#     errtype = {\n",
    "#             gdal.CE_None:'None',\n",
    "#             gdal.CE_Debug:'Debug',\n",
    "#             gdal.CE_Warning:'Warning',\n",
    "#             gdal.CE_Failure:'Failure',\n",
    "#             gdal.CE_Fatal:'Fatal'\n",
    "#     }\n",
    "#     err_msg = err_msg.replace('\\n',' ')\n",
    "#     err_class = errtype.get(err_class, 'None')\n",
    "#     print('Error Number: %s' % (err_num))\n",
    "#     print('Error Type: %s' % (err_class))\n",
    "#     print('Error Message: %s' % (err_msg))\n",
    "\n",
    "# if __name__=='__main__':\n",
    "\n",
    "#     # install error handler\n",
    "#     gdal.PushErrorHandler(gdal_error_handler)\n",
    "\n",
    "#     # Raise a dummy error\n",
    "#     gdal.Error(1, 2, 'test error')\n",
    "\n",
    "#     #uninstall error handler\n",
    "#     gdal.PopErrorHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 본격적으로 데이터를 읽어보자\n",
    "    - 래스터 데이터에 대한 개략적인 설명 : https://docs.qgis.org/2.18/ko/docs/gentle_gis_introduction/raster_data.html\n",
    "    - 래스터 데이터는 X, Y 좌표에 band라는 레이어를 쌓는 방식으로 구성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#래스터 데이터의 band값을 읽어오자\n",
    "# this allows GDAL to throw Python Exceptions\n",
    "gdal.UseExceptions()\n",
    "\n",
    "try:\n",
    "    src_ds =gdal.Open('gfsanl_3_20040401_0000_000.grb')\n",
    "except RuntimeError as e:\n",
    "    print('Unable to open')\n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    srcband = src_ds.GetRasterBand(1)\n",
    "except RuntimeError as  e:\n",
    "    # for example, try GetRasterBand(10)\n",
    "    print('Band ( %i ) not found' % band_num)\n",
    "    print(e)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-408.6, 267.6, 88.205992063492, 117.18251968807]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srcband.GetStatistics( True, True ) #Minimum, Maximum, Mean, StdDev를 읽어오는 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ RASTER BAND COUNT ]:  284\n"
     ]
    }
   ],
   "source": [
    "# 밴드의 카운트만큼 각 밴드의 기초통계값을 찍어준다\n",
    "if src_ds is None:\n",
    "    print('Unable to open')\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"[ RASTER BAND COUNT ]: \", src_ds.RasterCount)\n",
    "for band in range( src_ds.RasterCount ):\n",
    "    band += 1\n",
    "#     print(\"[ GETTING BAND ]: \", band)\n",
    "    srcband = src_ds.GetRasterBand(band)\n",
    "    if srcband is None:\n",
    "        continue\n",
    "\n",
    "    stats = srcband.GetStatistics( True, True )\n",
    "    if stats is None:\n",
    "        continue\n",
    "\n",
    "#     print(\"[ STATS ] =  Minimum=%.3f, Maximum=%.3f, Mean=%.3f, StdDev=%.3f\" % ( \\\n",
    "#                 stats[0], stats[1], stats[2], stats[3] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 래스터 데이터를 np.array로 다뤄보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 181 284\n"
     ]
    }
   ],
   "source": [
    "print(ds.RasterXSize, ds.RasterYSize, ds.RasterCount) #dataset의 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsA = ds.ReadAsArray() # array로 읽어온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284, 181, 360)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsA.shape # 3차원구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsT = dsA.transpose() # x,y 좌표별로 데이터를 다루고 싶기에 일단 transpose 시켜본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 181, 284)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsT[0][0].shape #그 결과 인덱싱하면 band별 관측치를 보여준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = []\n",
    "for x in range(ds.RasterXSize):\n",
    "    for y in range(ds.RasterYSize):\n",
    "        cells.append( (x,y, *dsT[x][y]) ) # x,y좌표를 기준으로 band별 관측치를 보려고 한다\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65160, 286)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array(cells) #cells 리스트를 다시 array로 변환한다\n",
    "A.shape #  결과는 360*181 == 65160의 row와 2+ 284의 col을 가진 이차원 array, 2004.04.01 00시의 데이터이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주성분 분석으로 feature의 수를 줄여보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50) # n_components 몇으로 해야할까? 일단 50으로 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = A[:,2:] #좌표정보를 제외한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X) #fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00589995e+21,  3.19612828e+18, -2.04071607e+04, ...,\n",
       "         1.30535187e+04,  3.81542022e+03,  1.09076842e+04],\n",
       "       [ 1.00589995e+21,  3.19612828e+18, -2.01824403e+04, ...,\n",
       "         1.30581766e+04,  3.81647057e+03,  1.09083671e+04],\n",
       "       [ 1.00589995e+21,  3.19612828e+18, -1.95624982e+04, ...,\n",
       "         1.30733719e+04,  3.82412183e+03,  1.08998697e+04],\n",
       "       ...,\n",
       "       [-9.93900048e+20,  3.15706195e+18,  5.69318949e+04, ...,\n",
       "        -1.29499209e+04, -3.96441137e+03, -1.08298403e+04],\n",
       "       [-9.93900048e+20,  3.15706195e+18,  5.71224897e+04, ...,\n",
       "        -1.29533622e+04, -3.96040497e+03, -1.08310124e+04],\n",
       "       [-9.93900048e+20,  3.15706195e+18,  5.75329009e+04, ...,\n",
       "        -1.29571404e+04, -3.96437898e+03, -1.08352400e+04]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z # 50차원으로 feature 수가 줄어들었다 이런식으로 줄어든 차원의 데이터를 클러스터링에 쓸수있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA를 위해 생각해볼 것\n",
    "\n",
    "1. PCA가 필요한가? 직접 필요한 변수 골라낼수없을까\n",
    "2. 날짜별로 feature의 수가 다른데 일괄적으로 차원축소 가능할까\n",
    "\n",
    "이후 구현 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w, U = np.linalg.eig(pca.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U.T.dot(A.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(Z[:,0], Z[:,1], c='r', s=100)\n",
    "# plt.title(\"transformed data\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
